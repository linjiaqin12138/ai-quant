#!/usr/bin/env python3
"""
è‚¡ç¥¨å¸‚åœºæƒ…ç»ªåˆ†æå·¥å…·
é€šè¿‡åˆ†æé›ªçƒå’Œè‚¡å§è¯„è®ºåŒºæ•°æ®ï¼Œç”Ÿæˆ0-100çš„æƒ…ç»ªè¯„åˆ†å’Œå¯¹åº”ç­‰çº§
"""

import os
import re
from datetime import datetime
import traceback
from typing import List, Dict, Any, Optional, Tuple
from textwrap import dedent

from jinja2 import Template
from lib.adapter.llm import get_llm, get_llm_direct_ask
from lib.adapter.llm.interface import LlmAbstract
from lib.utils.string import has_json_features
from lib.tools.json_fixer import JsonFixer
from lib.tools.web_page_reader import WebPageReader
from lib.tools.ashare_stock import get_ashare_stock_info, determine_exchange
from lib.logger import logger
from lib.utils.string import extract_json_string
from lib.utils.decorators import with_retry
from lib.model.error import LlmReplyInvalid

# HTMLæŠ¥å‘Šæ¨¡æ¿
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è‚¡ç¥¨å¸‚åœºæƒ…ç»ªåˆ†ææŠ¥å‘Š - {{ stock_symbol }}</title>
    <script src="https://cdn.jsdelivr.net/npm/marked@9.1.6/lib/marked.umd.js"></script>
    <style>
        body {
            font-family: 'Microsoft YaHei', Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            text-align: center;
            margin-bottom: 30px;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }
        h2 {
            color: #34495e;
            margin-top: 30px;
            margin-bottom: 15px;
            border-left: 4px solid #3498db;
            padding-left: 10px;
        }
        .sentiment-score {
            text-align: center;
            padding: 30px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 15px;
            margin: 20px 0;
            color: white;
        }
        .score-circle {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            background-color: {{ sentiment_color }};
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto 20px;
            font-size: 48px;
            font-weight: bold;
            color: white;
        }
        .sentiment-level {
            font-size: 24px;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .info-box {
            background-color: #ecf0f1;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .url-section {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 20px;
        }
        .comment {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 15px;
        }
        .comment-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
            padding-bottom: 8px;
            border-bottom: 1px solid #dee2e6;
        }
        .author {
            font-weight: bold;
            color: #2980b9;
        }
        .time {
            color: #7f8c8d;
            font-size: 0.9em;
        }
        .content {
            color: #2c3e50;
            margin-bottom: 10px;
        }
        .stats {
            display: flex;
            gap: 15px;
            font-size: 0.9em;
            color: #7f8c8d;
        }
        .sentiment-analysis {
            background-color: #e8f5e8;
            border: 1px solid #4caf50;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
        .analysis-content {
            line-height: 1.8;
        }
        /* Markdownæ¸²æŸ“æ ·å¼ä¼˜åŒ– */
        .analysis-content h1, .analysis-content h2, .analysis-content h3 {
            color: #2c3e50;
            margin-top: 25px;
            margin-bottom: 15px;
        }
        .analysis-content h1 {
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }
        .analysis-content h2 {
            border-left: 4px solid #3498db;
            padding-left: 10px;
        }
        .analysis-content h3 {
            color: #2980b9;
        }
        .analysis-content h4 {
            color: #16a085;
            margin-top: 20px;
            margin-bottom: 10px;
        }
        .analysis-content table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background-color: white;
        }
        .analysis-content th, .analysis-content td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        .analysis-content th {
            background-color: #f5f5f5;
            font-weight: bold;
        }
        .analysis-content tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        .analysis-content code {
            background-color: #f1f1f1;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
        }
        .analysis-content pre {
            background-color: #f8f8f8;
            border: 1px solid #e1e1e1;
            border-radius: 5px;
            padding: 15px;
            overflow-x: auto;
            margin: 15px 0;
        }
        .analysis-content blockquote {
            border-left: 4px solid #3498db;
            margin: 15px 0;
            padding: 10px 15px;
            background-color: #f0f7ff;
            font-style: italic;
        }
        .analysis-content ul, .analysis-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }
        .analysis-content li {
            margin: 8px 0;
        }
        .analysis-content strong {
            color: #2c3e50;
            font-weight: bold;
        }
        .analysis-content em {
            color: #7f8c8d;
            font-style: italic;
        }
        .raw-response {
            background-color: #2c3e50;
            color: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            overflow-x: auto;
            white-space: pre-wrap;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š è‚¡ç¥¨å¸‚åœºæƒ…ç»ªåˆ†ææŠ¥å‘Š</h1>
        
        <div class="info-box">
            <strong>è‚¡ç¥¨ä»£ç :</strong> {{ stock_symbol }}<br>
            <strong>è‚¡ç¥¨åç§°:</strong> {{ stock_name }}<br>
            <strong>è‚¡ç¥¨ç±»å‹:</strong> {{ stock_type }}<br>
            <strong>æ‰€å±è¡Œä¸š:</strong> {{ stock_business }}<br>
            <strong>äº¤æ˜“æ‰€:</strong> {{ exchange }}<br>
            <strong>åˆ†ææ—¶é—´:</strong> {{ analysis_time }}<br>
            <strong>æ€»è¯„è®ºæ•°:</strong> {{ total_comments }} æ¡<br>
            <strong>åˆ†æé¡µé¢:</strong> {{ url_results_count }} ä¸ª
        </div>
        
        <div class="sentiment-score">
            <div class="score-circle">{{ sentiment_score }}</div>
            <div class="sentiment-level">æƒ…ç»ªç­‰çº§: {{ sentiment_level }}</div>
            <div>å¸‚åœºæƒ…ç»ªè¯„åˆ†: {{ sentiment_score }}/100</div>
        </div>
        
        <div class="sentiment-analysis">
            <h3>ğŸ¤– AIæƒ…ç»ªåˆ†ææŠ¥å‘Š</h3>
            <div class="analysis-content" id="analysis-content"></div>
        </div>
        
        <h2>ğŸ“± å„å¹³å°è¯„è®ºç»Ÿè®¡</h2>
        {% for url_result in url_results %}
        <div class="url-section">
            <h3>å¹³å° {{ loop.index }}: {{ url_result.platform }}</h3>
            <p><strong>URL:</strong> <a href="{{ url_result.url }}" target="_blank">{{ url_result.url }}</a></p>
            <p><strong>è¯„è®ºæ•°é‡:</strong> {{ url_result.comments_count }} æ¡</p>
            
            <h4>è¯„è®ºå†…å®¹:</h4>
            {% if url_result.comments %}
                {% for comment in url_result.comments %}
                <div class="comment">
                    <div class="comment-header">
                        <span class="author">ğŸ‘¤ {{ comment.get('author', 'æœªçŸ¥ç”¨æˆ·') }}</span>
                        <span class="time">ğŸ• {{ comment.get('time', 'æœªçŸ¥æ—¶é—´') }}</span>
                    </div>
                    <div class="content">{{ comment.get('content', 'æ— å†…å®¹') }}</div>
                    <div class="stats">
                        <span>ğŸ‘ {{ comment.get('likes', 0) }} èµ</span>
                        <span>ğŸ’¬ {{ comment.get('replies', 0) }} å›å¤</span>
                    </div>
                </div>
                {% endfor %}
            {% else %}
                <p><em>æœªè·å–åˆ°è¯„è®ºå†…å®¹</em></p>
            {% endif %}
        </div>
        {% endfor %}
        
        <div style="text-align: center; margin-top: 30px; color: #7f8c8d; font-size: 0.9em;">
            <p>æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {{ current_time }}</p>
            <p>ç”±è‚¡ç¥¨å¸‚åœºæƒ…ç»ªåˆ†æAgentè‡ªåŠ¨ç”Ÿæˆ</p>
            <p>âš ï¸ æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®</p>
        </div>
    </div>
    
    <script>
        // åˆå§‹åŒ–markedé…ç½®
        marked.setOptions({
            breaks: true,
            gfm: true,
            headerIds: false,
            mangle: false
        });
        
        // è·å–åŸå§‹markdownå†…å®¹å¹¶æ¸²æŸ“
        const markdownContent = `{{ escaped_content }}`;
        const htmlContent = marked.parse(markdownContent);
        document.getElementById('analysis-content').innerHTML = htmlContent;
    </script>
</body>
</html>
"""

# è¯„è®ºæå–å™¨ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
COMMENT_EXTRACTOR_SYS_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»ç½‘é¡µå†…å®¹ä¸­æå–å’Œåˆ†æè‚¡ç¥¨ç›¸å…³ä¿¡æ¯ã€‚
ç°åœ¨æ—¶é—´æ˜¯{curr_time_str}ã€‚
è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚æ“ä½œï¼š
1. ä»”ç»†åˆ†æé¡µé¢å†…å®¹ï¼Œæ‰¾å‡ºè¯„è®ºåŒºåŸŸ
2. æå–è¿‡å»24å°æ—¶å†…çš„è¯„è®ºï¼ŒåŒ…æ‹¬ï¼š
   - è¯„è®ºè€…ç”¨æˆ·å/æ˜µç§°
   - è¯„è®ºæ—¶é—´
   - è¯„è®ºå†…å®¹
   - ç‚¹èµæ•°ã€é˜…è¯»æ•°ã€å›å¤æ•°ç­‰äº’åŠ¨æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
3. ä»¥JSONæ•°ç»„æ ¼å¼è¿”å›æ‰€æœ‰è¯„è®ºæ•°æ®

å¦‚æœé¡µé¢æ²¡æœ‰è¯„è®ºåŒºæˆ–è¯„è®ºä¸ºç©ºï¼Œè¯·è¯´æ˜å…·ä½“æƒ…å†µã€‚

Response Format Example (è¯·ä¸¥æ ¼follow)
[
    {{
        "author": "ç”¨æˆ·å",
        "time": "è¯„è®ºæ—¶é—´",
        "content": "è¯„è®ºå†…å®¹",
        "likes": 0,
        "replies": 0
    }},
    ...
]
"""

# æƒ…ç»ªåˆ†æå™¨ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
SENTIMENT_ANALYZER_SYS_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨å¸‚åœºæƒ…ç»ªåˆ†æä¸“å®¶ï¼Œæ“…é•¿åˆ†ææŠ•èµ„è€…è¯„è®ºå¹¶è¯„ä¼°å¸‚åœºæƒ…ç»ªã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. åˆ†æç”¨æˆ·æä¾›çš„è‚¡ç¥¨è¯„è®ºæ•°æ®
2. ç»¼åˆè€ƒè™‘è¯„è®ºå†…å®¹ã€ç‚¹èµæ•°ã€å›å¤æ•°ç­‰å› ç´ 
3. ç”Ÿæˆ0-100çš„æƒ…ç»ªè¯„åˆ†å’Œå¯¹åº”ç­‰çº§
4. æä¾›è¯¦ç»†çš„åˆ†ææŠ¥å‘Š

æƒ…ç»ªç­‰çº§åˆ’åˆ†ï¼š
- 0-20: æåº¦ææ…Œ (Extreme Fear)
- 21-40: ææ…Œ (Fear)  
- 41-60: ä¸­ç­‰ (Neutral)
- 61-80: è´ªå©ª (Greed)
- 81-100: æåº¦è´ªå©ª (Extreme Greed)

åˆ†æç»´åº¦ï¼š
1. è¯„è®ºæƒ…ç»ªå€¾å‘ï¼šç§¯æ/æ¶ˆæ/ä¸­æ€§è¯„è®ºçš„æ¯”ä¾‹
2. äº’åŠ¨çƒ­åº¦ï¼šç‚¹èµæ•°ã€å›å¤æ•°åæ˜ çš„å…³æ³¨åº¦
3. æƒ…ç»ªå¼ºåº¦ï¼šä½¿ç”¨çš„è¯æ±‡å¼ºåº¦å’Œæƒ…ç»ªè¡¨è¾¾
4. å¸‚åœºé¢„æœŸï¼šå¯¹æœªæ¥èµ°åŠ¿çš„é¢„æµ‹å€¾å‘

è¯·åœ¨æœ€åç”¨XMLæ ‡ç­¾ç»™å‡ºç»“æœï¼š
<sentiment_score>æ•°å€¼</sentiment_score>
<sentiment_level>ç­‰çº§</sentiment_level>
"""

LLM_RETRY_TIME = 1

class StockSentimentAnalyzer:
    """è‚¡ç¥¨å¸‚åœºæƒ…ç»ªåˆ†æå™¨"""
    
    def __init__(
            self, 
            llm: LlmAbstract = None,
            web_page_reader: Optional[WebPageReader] = None,
            json_fixer: Optional[JsonFixer] = None
        ):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.llm = llm or get_llm("paoluz", "deepseek-v3", temperature=0.2)
        
        # åˆ›å»ºè¯„è®ºæå–å·¥å…·
        self.comment_extractor = get_llm_direct_ask(
            system_prompt=COMMENT_EXTRACTOR_SYS_PROMPT_TEMPLATE.format(curr_time_str=datetime.now().strftime('%Y-%m-%d %H:%M:%S')),
            llm = self.llm,
            response_format="json_object"
        )
        
        # åˆ›å»ºæƒ…ç»ªåˆ†æå·¥å…·
        self.sentiment_analyzer = get_llm_direct_ask(
            system_prompt=SENTIMENT_ANALYZER_SYS_PROMPT_TEMPLATE,
            llm = self.llm
        )

        self.web_page_reader = web_page_reader or WebPageReader(llm=self.llm)
        # Fix Json Tool
        self.fix_json_tool = json_fixer.fix if json_fixer else JsonFixer(llm=self.llm).fix
    
    def _validate_comment_schema(self, comment: Any) -> bool:
        """
        éªŒè¯è¯„è®ºæ•°æ®çš„schemaæ˜¯å¦ç¬¦åˆè¦æ±‚
        
        Args:
            comment: è¯„è®ºæ•°æ®å¯¹è±¡
            
        Returns:
            bool: æ˜¯å¦ç¬¦åˆschemaè¦æ±‚
        """
        if not isinstance(comment, dict):
            return False
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ['author', 'time', 'content']
        for field in required_fields:
            if field not in comment:
                return False
            if not isinstance(comment[field], str):
                return False
            if not comment[field].strip():  # ä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²
                return False
        
        # æ£€æŸ¥å¯é€‰çš„æ•°å€¼å­—æ®µ
        optional_numeric_fields = ['likes', 'replies']
        for field in optional_numeric_fields:
            if field in comment:
                if not isinstance(comment[field], (int, float)):
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
                    try:
                        comment[field] = int(comment[field])
                    except (ValueError, TypeError):
                        comment[field] = 0
        
        return True
    
    def build_ashare_stock_dicussion_urls(self, stock_symbol: str, exchange: str) -> List[str]:
        """
        æ„å»ºè‚¡ç¥¨é¡µé¢URL
        
        Args:
            stock_symbol: è‚¡ç¥¨ä»£ç 
            exchange: äº¤æ˜“æ‰€ä»£ç (SH/SZ)
            
        Returns:
            URLåˆ—è¡¨
        """
        urls = []
        
        # é›ªçƒURL - éœ€è¦åŠ ä¸Šäº¤æ˜“æ‰€å‰ç¼€
        xueqiu_symbol = f"{exchange}{stock_symbol}"
        xueqiu_url = f"https://xueqiu.com/S/{xueqiu_symbol}"
        urls.append(xueqiu_url)
        
        # ä¸œæ–¹è´¢å¯Œè‚¡å§URL
        guba_url = f"https://guba.eastmoney.com/list,{stock_symbol}.html"
        urls.append(guba_url)
        
        return urls
    
    def _filter_valid_comments(self, json_list: list) -> list:
        # éªŒè¯æ¯æ¡è¯„è®ºçš„schema
        valid_comments = []
        invalid_comments = []
        for comment in json_list:
            if self._validate_comment_schema(comment):
                valid_comments.append(comment)
            else:
                invalid_comments.append(comment)
                logger.warning("å‘ç°%dæ¡ä¸ç¬¦åˆschemaçš„è¯„è®ºæ•°æ®, å¦‚%r", len(invalid_comments), invalid_comments[0])
        if not valid_comments:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„è¯„è®ºæ•°æ®")
        return valid_comments

    def extract_comments_from_url(self, url: str) -> Tuple[str, List[Dict[str, Any]]]:
        """
        ä»å•ä¸ªURLæå–è¯„è®º
        
        Args:
            url: é¡µé¢URL
            
        Returns:
            Tuple[åŸå§‹å“åº”, è¯„è®ºåˆ—è¡¨]
        """
        # ç›´æ¥è°ƒç”¨read_page_contentè·å–é¡µé¢å†…å®¹
        logger.info(f"æ­£åœ¨è·å–é¡µé¢å†…å®¹: {url}")
        page_content = self.web_page_reader.read_and_extract(url, 'æå–è¯„è®ºåŒº')
        
        # ä½¿ç”¨LLMåˆ†æé¡µé¢å†…å®¹å¹¶æå–è¯„è®º, æˆªå–å‰15000ä¸ªå­—ç¬¦ä»¥é¿å…è¿‡é•¿
        
        prompt = dedent(f"""
            è¯·åˆ†æä»¥ä¸‹é¡µé¢å†…å®¹ï¼Œæå–å…¶ä¸­çš„è¯„è®ºåŒºä¿¡æ¯ï¼š

            é¡µé¢URL: {url}
            é¡µé¢å†…å®¹: {page_content[:15000]}

            è¯·æå–æ‰€æœ‰è¯„è®ºå¹¶æŒ‰JSONæ ¼å¼è¿”å›ã€‚
        """)
        
        @with_retry((LlmReplyInvalid,), LLM_RETRY_TIME)
        def retryable_extract():
            logger.info(f"å¼€å§‹åˆ†æé¡µé¢: {url}")
            response = self.comment_extractor(prompt)
            logger.info("åˆ†æé¡µé¢å†…å®¹å®Œæˆï¼š%s...%s", response[:1], response[-1:])
            logger.debug("å®Œæ•´åˆ†æç»“æœ: %s", response)
            
            json_or_none = extract_json_string(response)
            logger.debug("æå–åˆ°çš„JSONå¯¹è±¡: %r", json_or_none)
            if json_or_none and isinstance(json_or_none, list):
                # éªŒè¯æ¯æ¡è¯„è®ºçš„schema
                return response, self._filter_valid_comments(json_or_none)
            else:
                logger.warning("å¤§æ¨¡å‹JSONå“åº”é”™è¯¯")
                # å°è¯•ä½¿ç”¨å¤§æ¨¡å‹ä¿®å¤JSON
                if has_json_features(response) and json_or_none is None:
                    logger.info("æ£€æµ‹åˆ°JSONç‰¹å¾å­—ç¬¦ï¼Œå°è¯•ä½¿ç”¨å¤§æ¨¡å‹ä¿®å¤")
                    fixed_json = self.fix_json_tool(response)
                    if fixed_json and isinstance(fixed_json, list):
                        return response, self._filter_valid_comments(fixed_json)
                    else:
                        logger.warning("å¤§æ¨¡å‹ä¿®å¤JSONå¤±è´¥ %s", fixed_json)
                else:
                    logger.error("å“åº”ä¸­æœªæ£€æµ‹åˆ°JSONç‰¹å¾å­—ç¬¦")
                
                raise LlmReplyInvalid("æœªæ‰¾åˆ°JSONæ ¼å¼çš„è¯„è®ºæ•°æ®", response)
        
        return retryable_extract()
    
    @with_retry((LlmReplyInvalid,), LLM_RETRY_TIME)
    def analyze_sentiment(self, stock_symbol: str, stock_name: str, all_comments: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†æå¸‚åœºæƒ…ç»ª
        
        Args:
            stock_symbol: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            all_comments: æ‰€æœ‰è¯„è®ºæ•°æ®
            
        Returns:
            æƒ…ç»ªåˆ†æç»“æœ
        """
        assert len(all_comments) > 0, "è¯„è®ºæ•°æ®ä¸èƒ½ä¸ºç©º"
        
        # å‡†å¤‡è¯„è®ºæ•°æ®
        comments_summary = self._prepare_comments_for_analysis(all_comments)
        
        prompt = dedent(f"""
            è¯·åˆ†æä»¥ä¸‹è‚¡ç¥¨ {stock_name}({stock_symbol}) çš„è¯„è®ºæ•°æ®ï¼Œè¯„ä¼°å½“å‰å¸‚åœºæƒ…ç»ªï¼š

            è¯„è®ºæ•°æ®ç»Ÿè®¡ï¼š
            - æ€»è¯„è®ºæ•°: {len(all_comments)}
            - æ€»ç‚¹èµæ•°: {sum(comment.get('likes', 0) for comment in all_comments)}
            - æ€»å›å¤æ•°: {sum(comment.get('replies', 0) for comment in all_comments)}

            è¯„è®ºå†…å®¹ç¤ºä¾‹ï¼š
            {comments_summary}

            è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š
            1. æ•´ä½“æƒ…ç»ªå€¾å‘ (ç§¯æ/æ¶ˆæ/ä¸­æ€§)
            2. äº’åŠ¨æ´»è·ƒåº¦ (ç‚¹èµå’Œå›å¤æƒ…å†µ)
            3. æƒ…ç»ªå¼ºåº¦ (ç”¨è¯æ¿€çƒˆç¨‹åº¦)
            4. å¸‚åœºé¢„æœŸ (çœ‹æ¶¨/çœ‹è·Œå€¾å‘)

            æœ€åç»™å‡º0-100çš„æƒ…ç»ªè¯„åˆ†å’Œå¯¹åº”ç­‰çº§ï¼Œå¹¶ç”¨XMLæ ‡ç­¾æ ‡æ³¨ã€‚
        """)
        
        logger.info(f"å¼€å§‹åˆ†æè‚¡ç¥¨ {stock_symbol} çš„å¸‚åœºæƒ…ç»ª")
        response = self.sentiment_analyzer(prompt)
        logger.info("å®Œæˆæƒ…ç»ªåˆ†æ")
        
        # æå–XMLæ ‡ç­¾ä¸­çš„æ•°æ®
        score_match = re.search(r'<sentiment_score>(\d+)</sentiment_score>', response)
        level_match = re.search(r'<sentiment_level>([^<]+)</sentiment_level>', response)
        
        if not score_match or not level_match:
            logger.error("æƒ…ç»ªåˆ†æç»“æœä¸­æœªæ‰¾åˆ°è¯„åˆ†æˆ–ç­‰çº§ä¿¡æ¯")
            raise LlmReplyInvalid("æƒ…ç»ªåˆ†æç»“æœæ ¼å¼é”™è¯¯", response)
        
        score = int(score_match.group(1)) if score_match else 50
        level = level_match.group(1) if level_match else "ä¸­ç­‰"
        
        return {
            "score": score,
            "level": level,
            "report": response,
            "raw_response": response
        }
    
    def _prepare_comments_for_analysis(self, comments: List[Dict[str, Any]], max_comments: int = 20) -> str:
        """
        å‡†å¤‡è¯„è®ºæ•°æ®ä¾›åˆ†æä½¿ç”¨
        
        Args:
            comments: è¯„è®ºåˆ—è¡¨
            max_comments: æœ€å¤§è¯„è®ºæ•°é‡
            
        Returns:
            æ ¼å¼åŒ–çš„è¯„è®ºå­—ç¬¦ä¸²
        """
        if not comments:
            return "æ— è¯„è®ºæ•°æ®"
        
        
        # æŒ‰ç‚¹èµæ•°æ’åºï¼Œå–å‰max_commentsæ¡
        sorted_comments = sorted(comments, key=lambda x: x.get('likes', 0), reverse=True)
        selected_comments = sorted_comments[:max_comments]
        
        comment_strings = []
        for i, comment in enumerate(selected_comments, 1):
            comment_str = f"""
{i}. [{comment.get('author', 'åŒ¿åç”¨æˆ·')}] {comment.get('time', 'æœªçŸ¥æ—¶é—´')}
å†…å®¹: {comment.get('content', 'è¯„è®ºå†…å®¹ç¼ºå¤±')}
ç‚¹èµ: {comment.get('likes', 0)} | å›å¤: {comment.get('replies', 0)}
"""
            comment_strings.append(comment_str)
        
        return "\n".join(comment_strings)
    
    def analyze_stock_sentiment(self, stock_symbol: str) -> Dict[str, Any]:
        """
        åˆ†æè‚¡ç¥¨å¸‚åœºæƒ…ç»ª
        
        Args:
            stock_symbol: è‚¡ç¥¨ä»£ç 
            
        Returns:
            å®Œæ•´çš„åˆ†æç»“æœ
        """
        result = { "success": False, 'stock_symbol': stock_symbol }
        try:
            logger.info(f"å¼€å§‹åˆ†æè‚¡ç¥¨ {stock_symbol} çš„å¸‚åœºæƒ…ç»ª")

            # 1. è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_info = get_ashare_stock_info(stock_symbol)
            stock_name = stock_info.get('stock_name', 'æœªçŸ¥è‚¡ç¥¨')
            result["stock_info"] = stock_info
            result["stock_name"] = stock_name
            logger.info(f"è·å–åˆ°è‚¡ç¥¨ä¿¡æ¯: {stock_name}")

            # 2. åˆ¤æ–­äº¤æ˜“æ‰€
            exchange = determine_exchange(stock_symbol)
            result["exchange"] = exchange
            logger.info(f"åˆ¤æ–­äº¤æ˜“æ‰€: {exchange}")
        
            # 3. æ„å»ºURL
            urls = self.build_ashare_stock_dicussion_urls(stock_symbol, exchange)
            logger.info(f"æ„å»ºURL: {urls}")
        
            # 4. çˆ¬å–è¯„è®º
            all_comments = []
            url_results = []
            for url in urls:
                try:
                    logger.info(f"çˆ¬å–é¡µé¢: {url}")
                    raw_response, comments = self.extract_comments_from_url(url)
                    
                    url_results.append({
                        "success": True,
                        "url": url,
                        "comments_count": len(comments),
                        "comments": comments,
                        "raw_response": raw_response
                    })
                    
                    all_comments.extend(comments)
                    logger.info(f"ä» {url} è·å–åˆ° {len(comments)} æ¡è¯„è®º")
                    
                except Exception as e:
                    logger.error(f"çˆ¬å–é¡µé¢ {url} å¤±è´¥: {e}")
                    logger.debug(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                    url_results.append({
                        "success": False,
                        "url": url,
                    })
            result["urls"] = urls
            result["url_results"] = url_results
            result["all_comments"] = all_comments
            result["total_comments"] = len(all_comments)

            if not all_comments:
                logger.warning(f"æ²¡æœ‰è¯„è®ºæ•°æ®ï¼Œæ— æ³•è¿›è¡Œæƒ…ç»ªåˆ†æ: {stock_symbol}")
                return result
            # 5. åˆ†æå¸‚åœºæƒ…ç»ª
            sentiment_result = self.analyze_sentiment(stock_symbol, stock_name, all_comments)
            result['analysis_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            result['sentiment_score'] = sentiment_result['score']
            result['sentiment_level'] = sentiment_result['level']
            result['sentiment_report'] = sentiment_result['report']
            
            logger.info(f"å®Œæˆæƒ…ç»ªåˆ†æ: {stock_symbol} - è¯„åˆ†: {sentiment_result['score']} - ç­‰çº§: {sentiment_result['level']}")
            result["success"] = True

        except Exception as e:
            logger.error(f"åˆ†æè‚¡ç¥¨ {stock_symbol} æƒ…ç»ªå¤±è´¥: {e}")
            logger.debug(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            
        return result

    def generate_html_report(self, analysis_result: Dict[str, Any]) -> str:
        """
        ç”ŸæˆHTMLæŠ¥å‘Š
        
        Args:
            analysis_result: åˆ†æç»“æœ
            
        Returns:
            HTMLæŠ¥å‘Šå­—ç¬¦ä¸²
        """
        
        stock_symbol = analysis_result["stock_symbol"]
        # æ ¹æ®æƒ…ç»ªè¯„åˆ†ç¡®å®šé¢œè‰²
        score = analysis_result["sentiment_score"]
        if score <= 20:
            sentiment_color = "#d32f2f"  # çº¢è‰² - æåº¦ææ…Œ
        elif score <= 40:
            sentiment_color = "#f57c00"  # æ©™è‰² - ææ…Œ
        elif score <= 60:
            sentiment_color = "#616161"  # ç°è‰² - ä¸­ç­‰
        elif score <= 80:
            sentiment_color = "#388e3c"  # ç»¿è‰² - è´ªå©ª
        else:
            sentiment_color = "#1976d2"  # è“è‰² - æåº¦è´ªå©ª
        
        # é¢„å¤„ç†markdownå†…å®¹ï¼Œè½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
        markdown_content = analysis_result["sentiment_report"]
        escaped_content = markdown_content.replace("\\", "\\\\").replace("`", "\\`").replace("${", "\\${")
        
        # å¤„ç†URLç»“æœï¼Œæ·»åŠ å¹³å°ä¿¡æ¯
        processed_url_results = []
        for url_result in analysis_result["url_results"]:
            platform = "é›ªçƒ" if "xueqiu.com" in url_result["url"] else "è‚¡å§" if "guba.eastmoney.com" in url_result["url"] else "å…¶ä»–å¹³å°"
            processed_url_result = url_result.copy()
            processed_url_result["platform"] = platform
            processed_url_results.append(processed_url_result)
        
        # æ¸²æŸ“HTMLå†…å®¹
        html_content = Template(HTML_TEMPLATE).render(
            stock_symbol=stock_symbol,
            stock_name=analysis_result["stock_name"],
            stock_type=analysis_result["stock_info"].get("stock_type", "æœªçŸ¥"),
            stock_business=analysis_result["stock_info"].get("stock_business", "æœªçŸ¥"),
            exchange=analysis_result["exchange"],
            analysis_time=analysis_result["analysis_time"],
            total_comments=analysis_result["total_comments"],
            url_results_count=len(analysis_result["url_results"]),
            sentiment_score=analysis_result["sentiment_score"],
            sentiment_level=analysis_result["sentiment_level"],
            sentiment_color=sentiment_color,
            escaped_content=escaped_content,
            url_results=processed_url_results,
            current_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        )
        
        return html_content
    
    def save_html_report(self, analysis_result: Dict[str, Any], save_folder_path: Optional[str] = None) -> str:
        """
        ä¿å­˜HTMLæŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶å¤¹
        
        Args:
            analysis_result: åˆ†æç»“æœ
            save_folder_path: ä¿å­˜æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰ç›®å½•
            
        Returns:
            HTMLæ–‡ä»¶è·¯å¾„
        """
        if save_folder_path is None:
            save_folder_path = os.getcwd()
        
        if not os.path.exists(save_folder_path):
            os.makedirs(save_folder_path)
        
        file_name = f"{analysis_result['stock_symbol']}_sentiment_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        file_path = os.path.join(save_folder_path, file_name)
        
        html_content = self.generate_html_report(analysis_result)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        logger.info(f"HTMLæŠ¥å‘Šå·²ä¿å­˜åˆ°: {file_path}")
        return file_path